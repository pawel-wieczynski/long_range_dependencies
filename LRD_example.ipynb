{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate toy dataset: random matrix $X$ of dim $N \\times d$, where $N=800$ denotes number of tokens and $d = 100$ denotes dimensionality of embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 800\n",
    "d = 100\n",
    "\n",
    "np.random.seed(213)\n",
    "X = np.random.randn(N, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate cosine correlation between two random vectors $U$ and $V$ as:\n",
    "$$\n",
    "\\operatorname{Coco}(U,V) = \\mathbb{E} \\left[ \\overline{U} \\cdot \\overline{V} \\right] - \\mathbb{E} \\left[ \\overline{U} \\right] \\cdot \\mathbb{E} \\left[ \\overline{V} \\right]\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "\\overline{U} = \\frac{U}{||U||}, \\quad \\overline{V} = \\frac{V}{||V||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: compute and cache normalized unpooled embeddings:\n",
    "$$\n",
    "\\overline{X}_i = \\frac{X_i}{||X_i||}\n",
    "$$\n",
    "\n",
    "where $\\overline{X}_i$ is normalized embedding of $i$-th token, $i=1, 2, \\dots, N$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate norms\n",
    "norms = np.linalg.norm(X, axis=1, keepdims=True) # shape (N, 1)\n",
    "\n",
    "# Avoid division by zero\n",
    "norms[norms == 0] = 1.0\n",
    "\n",
    "# Normalize embeddings\n",
    "X_normalized = X / norms # shape (N, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: compute and cache prefix sums:\n",
    "$$\n",
    "S_{k} = \\sum_{i=1}^{k-1} \\overline{X}_{i}\n",
    "$$\n",
    "\n",
    "for $k = 0, 1, \\dots, N$. Each prefix sum $S_k$ is a $d$-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros((N+1, d))\n",
    "S[1:] = np.cumsum(X_normalized, axis=0) # shape (N+1, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix lag $l = 5.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 5\n",
    "length = N - l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Calculate \n",
    "$$\n",
    "\\mathbb{E} \\left[ \\overline{U} \\right] = \\frac{S_{N-l} - S_0}{N - l} = \\frac{1}{N - l} \\sum_{i=1}^{N-l} \\overline{X}_i\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\mathbb{E} \\left[ \\overline{V} \\right] = \\frac{S_{N} - S_l}{N - l} = \\frac{1}{N - l} \\sum_{i=l}^{N} \\overline{X}_i\n",
    "$$\n",
    "\n",
    "These expected values are $d$-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_U = (S[N-l] - S[0]) / length # shape (d,1)\n",
    "E_V = (S[N] - S[l]) / length # shape (d,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate dot product $\\mathbb{E} \\left[ \\overline{U} \\right] \\cdot \\mathbb{E} \\left[ \\overline{V} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_EV = np.dot(E_U, E_V) # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Calculate\n",
    "$$\n",
    "\\mathbb{E} \\left[ \\overline{U} \\cdot \\overline{V} \\right] = \\frac{1}{N-l} \\sum_{i=1}^{N-l} \\overline{X_i} \\cdot \\overline{X}_{i+l}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = X_normalized[:N-l] # shape (N-l, d)\n",
    "V = X_normalized[l:] # shape (N-l, d)\n",
    "dot_products = np.sum(U * V, axis=1) # shape (N-l, 1)\n",
    "E_UV = np.mean(dot_products) # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Return Coco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0018225311183616708"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_UV - EU_EV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
